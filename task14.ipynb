{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-14T12:12:49.402651200Z",
     "start_time": "2023-12-14T12:12:48.844652300Z"
    }
   },
   "outputs": [],
   "source": [
    "import random, numpy, gym, time, statistics\n",
    "from gym.envs.toy_text.frozen_lake import generate_random_map\n",
    "\n",
    "# constants\n",
    "LEFT, DOWN, RIGHT, UP = 0, 1, 2, 3\n",
    "FLOOR, EXPLORED, PATH, HOLE, DEADEND = 0, 1, 2, 3, 4\n",
    "dirs = {0: \"LEFT\", 1: \"DOWN\", 2: \"RIGHT\", 3: \"UP\"} # convenient direction dict for debug output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# this converts the 1D grid coordinate to a 2D coordinate\n",
    "def get_2d_pos(pos: int, map_size: int) -> tuple:\n",
    "    return int(pos % (map_size - 0)), int(pos / (map_size - 0))\n",
    "\n",
    "# manhattan distance heuristic formula\n",
    "def manhattan(a, b) -> int:\n",
    "    return sum(abs(val1-val2) for val1, val2 in zip(a, b))\n",
    "\n",
    "# this function updates the 2D grid coordinate based on the given action.\n",
    "def update_pos_for_action(action: int, pos: tuple) -> tuple:\n",
    "    if action == LEFT:\n",
    "        return pos[0] - 1, pos[1]\n",
    "    elif action == DOWN:\n",
    "        return pos[0], pos[1] + 1\n",
    "    elif action == RIGHT:\n",
    "        return pos[0] + 1, pos[1]\n",
    "    elif action == UP:\n",
    "        return pos[0], pos[1] - 1\n",
    "    \n",
    "# returns the action for a given 2d position offset. used for replaying actions to support slippery=True\n",
    "def get_action_for_pos_offset(pos: tuple) -> int:\n",
    "    if pos[0] == -1 and pos[1] == 0:\n",
    "        return LEFT\n",
    "    elif pos[0] == 0 and pos[1] == 1:\n",
    "        return DOWN\n",
    "    elif pos[0] == 1 and pos[1] == 0:\n",
    "        return RIGHT\n",
    "    elif pos[0] == 0 and pos[1] == -1:\n",
    "        return UP\n",
    "\n",
    "# this function returns True if the given action for the passed position results in a valid board target position.\n",
    "# if not, we are outside the game board.\n",
    "def is_action_valid(action: int, pos: tuple, map_size: int) -> bool:\n",
    "    if action == LEFT:\n",
    "        return pos[0] >= 0\n",
    "    elif action == DOWN:\n",
    "        return pos[1] <= map_size - 1\n",
    "    elif action == RIGHT:\n",
    "        return pos[0] <= map_size - 1\n",
    "    elif action == UP:\n",
    "        return pos[1] >= 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T12:12:49.418651400Z",
     "start_time": "2023-12-14T12:12:49.409651600Z"
    }
   },
   "id": "882e77e4ff727980"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# here we determine the suitable action for a given position and goal.\n",
    "# this function tries its best to cull non-optimal actions and selects a suitable one based on the lowest\n",
    "# manhattan distance from the current position and the goal position.\n",
    "def determine_action(env, pos: int, goal_pos: int, exploration: bool, map_size: int, grid: numpy.array, moves: list) -> int:\n",
    "    pos_2d = get_2d_pos(pos, map_size) # convert 1D state index to 2D grid coordinates\n",
    "    goal_pos_2d = get_2d_pos(goal_pos, map_size) # convert goal pos to 2D grid coordinates\n",
    "    lowest_dist = 9999 # keep track of the lowest distance for an action.\n",
    "    best_action = -1 # keep track of the best action found during iteration\n",
    "    for action in range(env.action_space.n): # loop over all actions within the action space\n",
    "        target_pos_2d = update_pos_for_action(action, pos_2d) # compute the resulting target 2D grid coord for this action\n",
    "\n",
    "        # if an action results in a target position outside the grid, we can skip this as a valid action\n",
    "        if not is_action_valid(action, target_pos_2d, map_size):\n",
    "            # print(f\"skipped: {dirs[action]}\")\n",
    "            continue\n",
    "\n",
    "        # Culling Adjacent Holes and Deadends\n",
    "        # if the target position has been identified as a deadend or hole during a previous episode,\n",
    "        # remove it from the moves dict for this current pos_2d.\n",
    "        grid_val = grid[target_pos_2d[1], target_pos_2d[0]]\n",
    "        if grid_val == DEADEND or grid_val == HOLE:\n",
    "            # only avoid moving to deadends or holes if we are currently standing on one\n",
    "            if grid[pos_2d[1], pos_2d[0]] == FLOOR or grid[pos_2d[1], pos_2d[0]] == EXPLORED:\n",
    "                # print(f\"skipped {dirs[action]} was hole: {target_pos_2d}\")\n",
    "                if pos_2d in moves and target_pos_2d in moves[pos_2d]:\n",
    "                    moves[pos_2d].remove(target_pos_2d) # remove valid move as it has been discovered as a hole\n",
    "                continue\n",
    "\n",
    "        # Deadend detection\n",
    "        # if this action results in a position, where the only next valid from is our *current* position *and* it\n",
    "        # is the only valid move for that target position then it has to be skipped and never visited in future to\n",
    "        # avoid cyclic moves and optimise the simulation\n",
    "        if target_pos_2d in moves and pos_2d in moves[target_pos_2d] and len(moves[target_pos_2d]) <= 1 and grid_val == EXPLORED and target_pos_2d != (0, 0):\n",
    "            # print(f\"skipped cyclic move {dirs[action]}: {target_pos_2d}\")\n",
    "            # treat this dead-end as a hole for an early escape\n",
    "            grid[target_pos_2d[1], target_pos_2d[0]] = DEADEND\n",
    "            continue\n",
    "\n",
    "        # make sure the dict keys for this pos and target pos exist\n",
    "        if not pos_2d in moves:\n",
    "            moves[pos_2d] = set()\n",
    "\n",
    "        # If a position has been explored (more than two valid moves) then upgrade this cell to allow culling\n",
    "        if grid[pos_2d[1], pos_2d[0]] == FLOOR and len(moves[pos_2d]) >= 1:\n",
    "            grid[pos_2d[1], pos_2d[0]] = EXPLORED\n",
    "\n",
    "        # if the adjacent position for pos_2d has not ever been visited, visit it to discover its state\n",
    "        # this is an optional extra that requires more episodes to reach the goal, but it also discovers\n",
    "        # more of the game board doing so. This could potentially be used to \"train\" an agent\n",
    "        # before navigating the game like usual. Otherwise pick based on best man dist.\n",
    "        if target_pos_2d not in moves[pos_2d] and exploration:\n",
    "            best_action = action\n",
    "            moves[pos_2d].add(target_pos_2d)\n",
    "            break # stop iterating as we want to explore this action\n",
    "\n",
    "        # keep note of all valid moves for this position, even if its not the most optimal in terms of man dist\n",
    "        moves[pos_2d].add(target_pos_2d)\n",
    "\n",
    "        # calculate the manhattan distance, suitable for distances within 2D grids\n",
    "        man_dist = manhattan(target_pos_2d, goal_pos_2d)\n",
    "\n",
    "        # test if the dist is equal the best best distance thus far, and choose between them at random.\n",
    "        # this tries to avoid the situation where the agent will always pick DOWN (since its first in order)\n",
    "        # which could be a hole, instead of going RIGHT (which has the same dist)\n",
    "        if man_dist == lowest_dist:\n",
    "            best_action = random.choice([best_action, action])\n",
    "        # record new lowest dist and the action for that distance\n",
    "        elif man_dist < lowest_dist:\n",
    "            lowest_dist = man_dist\n",
    "            best_action = action\n",
    "\n",
    "    # sanity check: if we reach this condition, the algorithm is flawed as FrozenLake is generated\n",
    "    # so there is at least one valid path to the goal.\n",
    "    if best_action == -1:\n",
    "        print(f\"Error: no valid actions!!!\")\n",
    "\n",
    "    # print(f\"moves for {pos_2d}: {moves[pos_2d]}\")\n",
    "    return best_action"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T12:12:49.439649300Z",
     "start_time": "2023-12-14T12:12:49.419650800Z"
    }
   },
   "id": "263a5809461de31b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# the main simulation loop. this will iterate for x episodes and will infinitely loop until we either\n",
    "#reach the goal or hit a hole. additionally it will generate new observations and update the grid\n",
    "#array when the agent finds a hole.\n",
    "def run_iterations(env, episodes: int, map_size: int, grid: numpy.array, moves: list, exploration=True) -> tuple:\n",
    "    goal_pos = map_size * map_size - 1 # calculate the goal pos for a given map size\n",
    "    for episode in range(episodes):\n",
    "        positions = list()\n",
    "        observation, _ = env.reset() # reset the environment for each new episode or run through the maze\n",
    "        while True: # infinite loop to either find goal or hole\n",
    "            prev_pos_2d = get_2d_pos(observation, map_size) # save a copy of the previous position so it can be used for debug output\n",
    "            # generate a suitable action from our custom algorithm\n",
    "            action = determine_action(env, observation, goal_pos, exploration, map_size, grid, moves)\n",
    "            # if the action is -1, then our algorithm reached an illegal state and we can to return and bail from the loop\n",
    "            if action == -1:\n",
    "                return None, None\n",
    "            # update the agent state based on the generated action\n",
    "            observation, reward, term, trunc, info = env.step(action)\n",
    "            # append action to action replay list\n",
    "            positions.append(get_2d_pos(observation, map_size))\n",
    "            # basic debug output to show the current episode, but rate limited as to not slow down simulations\n",
    "            if episode % 50000 == 0:\n",
    "                print(f\"({episode}) prev: {prev_pos_2d}, action: {dirs[action]}, result: {get_2d_pos(observation, map_size)}\")\n",
    "            # the simulation has reached a termination state, and we have found the goal\n",
    "            if term and reward == 1:\n",
    "                # steps_list.append(step)\n",
    "                print(f\"Found: {observation} {get_2d_pos(observation, map_size)} in {episode} episodes\")\n",
    "                return episode, positions\n",
    "            # the simulation has reached a termination state, and we fell into a hole\n",
    "            elif term and reward == 0:\n",
    "                # convert the new updated agent state position to a 2D grid coordinate\n",
    "                pos_2d = get_2d_pos(observation, map_size)\n",
    "                # update the grid array to record the presence of this hole for the next episodes\n",
    "                grid[pos_2d[1], pos_2d[0]] = HOLE\n",
    "                # print(f\"Hole: {get_2d_pos(observation)}\")\n",
    "                break\n",
    "\n",
    "# run a FrozenLake simulation with default parameters. slippery True as stated by the assessment\n",
    "def simulate(game_map: list, map_size: int, grid: numpy.array, moves: list, render: any, slippery: bool, exploration: bool, episodes: int) -> tuple:\n",
    "    env = gym.make('FrozenLake-v1', desc=game_map, is_slippery=slippery, render_mode=render)\n",
    "    start = time.time()\n",
    "    episode, positions = run_iterations(env, episodes, map_size, grid, moves, exploration=exploration)\n",
    "    end = time.time()\n",
    "    print(f\"Elapsed: {end - start}s\")  # print the elapsed seconds until the goal is found\n",
    "    return episode, positions, end - start"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T12:12:49.451652900Z",
     "start_time": "2023-12-14T12:12:49.434648400Z"
    }
   },
   "id": "ebc5a11896cc4ee2"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# this function runs the frozen lake simulation while also storing all the metrics needed while the simulation runs all of its iterations and episodes\n",
    "def run_metrics(game_map: list, map_size: int, iterations=1, render=None, slippery=True, exploration=False, pre_explore=False, episodes=1_000_000) -> list:\n",
    "    # small sanity check to make sure there isn't a custom map passed here that does not match the map_size, as that would break many things\n",
    "    if len(game_map) != map_size:\n",
    "        print(\"Map dimensions and map size do not match!\")\n",
    "        exit(1)\n",
    "\n",
    "    all_episodes = []\n",
    "    all_positions = []\n",
    "    all_seconds = []\n",
    "    for i in range(iterations):\n",
    "        print(f\"Running Iteration: {i + 1}\")\n",
    "        if game_map is None:\n",
    "            # generate a random map with the given map size and 30% chance of slipping\n",
    "            game_map = generate_random_map(size=map_size, p=0.3)\n",
    "        grid = numpy.zeros(shape=(map_size, map_size))  # grid to record the map layout discoveries for future episodes\n",
    "        moves = {}  # moves dict for recording valid moves for a given position\n",
    "\n",
    "        # if we want to pre explore, we want to do it without slippery being enabled and also force exploration of unknown tiles\n",
    "        if pre_explore:\n",
    "            print(\"Running pre exploration\")\n",
    "            simulate(game_map, map_size, grid, moves, render, False, True, episodes)\n",
    "            print(grid)\n",
    "\n",
    "        # run the frozen lake simulation\n",
    "        print(\"Running simulation\")\n",
    "        eps, positions, secs = simulate(game_map, map_size, grid, moves, render, slippery, exploration, episodes)\n",
    "        all_episodes.append(eps)\n",
    "        all_positions.append(positions)\n",
    "        all_seconds.append(secs)\n",
    "    avg_episodes = statistics.mean(all_episodes)\n",
    "    avg_seconds = statistics.fmean(all_seconds)\n",
    "    print(f\"Found the goal in an average of {avg_episodes} episodes and {avg_seconds} seconds.\")\n",
    "    return all_positions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T12:12:49.480650800Z",
     "start_time": "2023-12-14T12:12:49.456651Z"
    }
   },
   "id": "9f0111c40011e027"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# this function replays the list of positions returned by run_metrics. this is used to show the set of moves for the winning episode\n",
    "def replay_actions(game_map: list, all_positions: list, map_size: int) -> None:\n",
    "    env = gym.make('FrozenLake-v1', desc=game_map, is_slippery=False, render_mode=\"human\")\n",
    "    for positions in all_positions:\n",
    "        print(positions)\n",
    "        observation, _ = env.reset()  # reset the environment for each new episode or run through the maze\n",
    "        for pos in positions:\n",
    "            diff = tuple(x-y for x,y in zip(pos, get_2d_pos(observation, map_size)))\n",
    "            action = get_action_for_pos_offset(diff)\n",
    "            if action is None:\n",
    "                continue\n",
    "            observation, reward, term, trunc, info = env.step(action)\n",
    "            if (term or trunc) and reward == 1:\n",
    "                print(\"GOAL\")\n",
    "                return"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T12:12:49.486652600Z",
     "start_time": "2023-12-14T12:12:49.469652700Z"
    }
   },
   "id": "654a604d62518592"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Iteration: 1\n",
      "Running simulation\n",
      "(0) prev: (0, 0), action: RIGHT, result: (1, 0)\n",
      "(0) prev: (1, 0), action: RIGHT, result: (2, 0)\n",
      "(0) prev: (2, 0), action: DOWN, result: (1, 0)\n",
      "(0) prev: (1, 0), action: RIGHT, result: (1, 0)\n",
      "(0) prev: (1, 0), action: DOWN, result: (2, 0)\n",
      "(0) prev: (2, 0), action: RIGHT, result: (2, 0)\n",
      "(0) prev: (2, 0), action: DOWN, result: (1, 0)\n",
      "(0) prev: (1, 0), action: DOWN, result: (1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000) prev: (0, 0), action: RIGHT, result: (0, 0)\n",
      "(50000) prev: (0, 0), action: RIGHT, result: (1, 0)\n",
      "(50000) prev: (1, 0), action: RIGHT, result: (1, 0)\n",
      "(50000) prev: (1, 0), action: RIGHT, result: (1, 0)\n",
      "(50000) prev: (1, 0), action: RIGHT, result: (1, 1)\n",
      "(100000) prev: (0, 0), action: RIGHT, result: (0, 0)\n",
      "(100000) prev: (0, 0), action: RIGHT, result: (1, 0)\n",
      "(100000) prev: (1, 0), action: RIGHT, result: (1, 1)\n",
      "Found: 99 (9, 9) in 114794 episodes\n",
      "Elapsed: 26.1750009059906s\n",
      "Found the goal in an average of 114794 episodes and 26.1750009059906 seconds.\n",
      "[(1, 0), (2, 0), (2, 1), (3, 1), (2, 1), (3, 1), (2, 1), (3, 1), (3, 2), (4, 2), (5, 2), (6, 2), (7, 2), (8, 2), (9, 2), (9, 3), (9, 4), (9, 4), (9, 5), (9, 6), (9, 7), (9, 8), (9, 9)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOAL\n"
     ]
    }
   ],
   "source": [
    "random_map = generate_random_map(size=10, p=0.3)\n",
    "# standard_map = ['SFFHHHFFHH', 'FHFFHFHHHH', 'FHHFFFFFFF', 'HFHHFFHHFF', 'FHHFHHHHHF', 'HHHHHFHFFF', 'FHHHHHFFFF', 'HFFHHFFFHF', 'HHFHHHHFFF', 'HHFHHHHHFG']\n",
    "all_sim_positions = run_metrics(random_map, 10, iterations=1, pre_explore=False, slippery=True)\n",
    "time.sleep(5) # just to help with recording\n",
    "replay_actions(random_map, all_sim_positions, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-14T12:13:27.201651700Z",
     "start_time": "2023-12-14T12:12:49.484651700Z"
    }
   },
   "id": "fcdab5712f6bb087"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
